{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss \n",
      "epoch 0: \n",
      "0.461280227597\n",
      "\n",
      "validation_loss \n",
      "epoch 0: \n",
      "0.227846938446\n",
      "\n",
      "train_loss \n",
      "epoch 1: \n",
      "0.460864427597\n",
      "\n",
      "validation_loss \n",
      "epoch 1: \n",
      "0.227843338446\n",
      "\n",
      "train_loss \n",
      "epoch 2: \n",
      "0.460448627597\n",
      "\n",
      "validation_loss \n",
      "epoch 2: \n",
      "0.227839738446\n",
      "\n",
      "train_loss \n",
      "epoch 3: \n",
      "0.460032827597\n",
      "\n",
      "validation_loss \n",
      "epoch 3: \n",
      "0.227836138446\n",
      "\n",
      "train_loss \n",
      "epoch 4: \n",
      "0.459617027597\n",
      "\n",
      "validation_loss \n",
      "epoch 4: \n",
      "0.227832538446\n",
      "\n",
      "train_loss \n",
      "epoch 5: \n",
      "0.459201227597\n",
      "\n",
      "validation_loss \n",
      "epoch 5: \n",
      "0.227828938446\n",
      "\n",
      "train_loss \n",
      "epoch 6: \n",
      "0.458785427597\n",
      "\n",
      "validation_loss \n",
      "epoch 6: \n",
      "0.227825338446\n",
      "\n",
      "train_loss \n",
      "epoch 7: \n",
      "0.458369627597\n",
      "\n",
      "validation_loss \n",
      "epoch 7: \n",
      "0.227821738446\n",
      "\n",
      "train_loss \n",
      "epoch 8: \n",
      "0.457953827597\n",
      "\n",
      "validation_loss \n",
      "epoch 8: \n",
      "0.227818138446\n",
      "\n",
      "train_loss \n",
      "epoch 9: \n",
      "0.457538027597\n",
      "\n",
      "validation_loss \n",
      "epoch 9: \n",
      "0.227814538446\n",
      "\n",
      "train_loss \n",
      "epoch 10: \n",
      "0.457122227597\n",
      "\n",
      "validation_loss \n",
      "epoch 10: \n",
      "0.227810938446\n",
      "\n",
      "train_loss \n",
      "epoch 11: \n",
      "0.456706427597\n",
      "\n",
      "validation_loss \n",
      "epoch 11: \n",
      "0.227807338446\n",
      "\n",
      "train_loss \n",
      "epoch 12: \n",
      "0.456290627597\n",
      "\n",
      "validation_loss \n",
      "epoch 12: \n",
      "0.227803738446\n",
      "\n",
      "train_loss \n",
      "epoch 13: \n",
      "0.455874827597\n",
      "\n",
      "validation_loss \n",
      "epoch 13: \n",
      "0.227800138446\n",
      "\n",
      "train_loss \n",
      "epoch 14: \n",
      "0.455459027597\n",
      "\n",
      "validation_loss \n",
      "epoch 14: \n",
      "0.227796538446\n",
      "\n",
      "train_loss \n",
      "epoch 15: \n",
      "0.455043227597\n",
      "\n",
      "validation_loss \n",
      "epoch 15: \n",
      "0.227792938446\n",
      "\n",
      "train_loss \n",
      "epoch 16: \n",
      "0.454627427597\n",
      "\n",
      "validation_loss \n",
      "epoch 16: \n",
      "0.227789338446\n",
      "\n",
      "train_loss \n",
      "epoch 17: \n",
      "0.454211627597\n",
      "\n",
      "validation_loss \n",
      "epoch 17: \n",
      "0.227785738446\n",
      "\n",
      "train_loss \n",
      "epoch 18: \n",
      "0.453795827597\n",
      "\n",
      "validation_loss \n",
      "epoch 18: \n",
      "0.227782138446\n",
      "\n",
      "train_loss \n",
      "epoch 19: \n",
      "0.453380027597\n",
      "\n",
      "validation_loss \n",
      "epoch 19: \n",
      "0.227778538446\n",
      "\n",
      "train_loss \n",
      "epoch 20: \n",
      "0.452964227597\n",
      "\n",
      "validation_loss \n",
      "epoch 20: \n",
      "0.227774938446\n",
      "\n",
      "train_loss \n",
      "epoch 21: \n",
      "0.452548427597\n",
      "\n",
      "validation_loss \n",
      "epoch 21: \n",
      "0.227771338446\n",
      "\n",
      "train_loss \n",
      "epoch 22: \n",
      "0.452132627597\n",
      "\n",
      "validation_loss \n",
      "epoch 22: \n",
      "0.227767738446\n",
      "\n",
      "train_loss \n",
      "epoch 23: \n",
      "0.451716827597\n",
      "\n",
      "validation_loss \n",
      "epoch 23: \n",
      "0.227764138446\n",
      "\n",
      "train_loss \n",
      "epoch 24: \n",
      "0.451301027597\n",
      "\n",
      "validation_loss \n",
      "epoch 24: \n",
      "0.227760538446\n",
      "\n",
      "train_loss \n",
      "epoch 25: \n",
      "0.450885227597\n",
      "\n",
      "validation_loss \n",
      "epoch 25: \n",
      "0.227756938446\n",
      "\n",
      "train_loss \n",
      "epoch 26: \n",
      "0.450469427597\n",
      "\n",
      "validation_loss \n",
      "epoch 26: \n",
      "0.227753338446\n",
      "\n",
      "train_loss \n",
      "epoch 27: \n",
      "0.450053627597\n",
      "\n",
      "validation_loss \n",
      "epoch 27: \n",
      "0.227749738446\n",
      "\n",
      "train_loss \n",
      "epoch 28: \n",
      "0.449637827597\n",
      "\n",
      "validation_loss \n",
      "epoch 28: \n",
      "0.227746138446\n",
      "\n",
      "train_loss \n",
      "epoch 29: \n",
      "0.449222027597\n",
      "\n",
      "validation_loss \n",
      "epoch 29: \n",
      "0.227742538446\n",
      "\n",
      "train_loss \n",
      "epoch 30: \n",
      "0.448806227597\n",
      "\n",
      "validation_loss \n",
      "epoch 30: \n",
      "0.227738938446\n",
      "\n",
      "train_loss \n",
      "epoch 31: \n",
      "0.448390427597\n",
      "\n",
      "validation_loss \n",
      "epoch 31: \n",
      "0.227735338446\n",
      "\n",
      "train_loss \n",
      "epoch 32: \n",
      "0.447974627597\n",
      "\n",
      "validation_loss \n",
      "epoch 32: \n",
      "0.227731738446\n",
      "\n",
      "train_loss \n",
      "epoch 33: \n",
      "0.447558827597\n",
      "\n",
      "validation_loss \n",
      "epoch 33: \n",
      "0.227728138446\n",
      "\n",
      "train_loss \n",
      "epoch 34: \n",
      "0.447143027597\n",
      "\n",
      "validation_loss \n",
      "epoch 34: \n",
      "0.227724538446\n",
      "\n",
      "train_loss \n",
      "epoch 35: \n",
      "0.446727227597\n",
      "\n",
      "validation_loss \n",
      "epoch 35: \n",
      "0.227720938446\n",
      "\n",
      "train_loss \n",
      "epoch 36: \n",
      "0.446311427597\n",
      "\n",
      "validation_loss \n",
      "epoch 36: \n",
      "0.227717338446\n",
      "\n",
      "train_loss \n",
      "epoch 37: \n",
      "0.445895627597\n",
      "\n",
      "validation_loss \n",
      "epoch 37: \n",
      "0.227713738446\n",
      "\n",
      "train_loss \n",
      "epoch 38: \n",
      "0.445479827597\n",
      "\n",
      "validation_loss \n",
      "epoch 38: \n",
      "0.227710138446\n",
      "\n",
      "train_loss \n",
      "epoch 39: \n",
      "0.445064027597\n",
      "\n",
      "validation_loss \n",
      "epoch 39: \n",
      "0.227706538446\n",
      "\n",
      "train_loss \n",
      "epoch 40: \n",
      "0.444648227597\n",
      "\n",
      "validation_loss \n",
      "epoch 40: \n",
      "0.227702938446\n",
      "\n",
      "train_loss \n",
      "epoch 41: \n",
      "0.444232427597\n",
      "\n",
      "validation_loss \n",
      "epoch 41: \n",
      "0.227699338446\n",
      "\n",
      "train_loss \n",
      "epoch 42: \n",
      "0.443816627597\n",
      "\n",
      "validation_loss \n",
      "epoch 42: \n",
      "0.227695738446\n",
      "\n",
      "train_loss \n",
      "epoch 43: \n",
      "0.443400827597\n",
      "\n",
      "validation_loss \n",
      "epoch 43: \n",
      "0.227692138446\n",
      "\n",
      "train_loss \n",
      "epoch 44: \n",
      "0.442985027597\n",
      "\n",
      "validation_loss \n",
      "epoch 44: \n",
      "0.227688538446\n",
      "\n",
      "train_loss \n",
      "epoch 45: \n",
      "0.442569227597\n",
      "\n",
      "validation_loss \n",
      "epoch 45: \n",
      "0.227684938446\n",
      "\n",
      "train_loss \n",
      "epoch 46: \n",
      "0.442153427597\n",
      "\n",
      "validation_loss \n",
      "epoch 46: \n",
      "0.227681338446\n",
      "\n",
      "train_loss \n",
      "epoch 47: \n",
      "0.441737627597\n",
      "\n",
      "validation_loss \n",
      "epoch 47: \n",
      "0.227677738446\n",
      "\n",
      "train_loss \n",
      "epoch 48: \n",
      "0.441321827597\n",
      "\n",
      "validation_loss \n",
      "epoch 48: \n",
      "0.227674138446\n",
      "\n",
      "train_loss \n",
      "epoch 49: \n",
      "0.440906027597\n",
      "\n",
      "validation_loss \n",
      "epoch 49: \n",
      "0.227670538446\n",
      "\n",
      "train_loss \n",
      "epoch 50: \n",
      "0.440490227597\n",
      "\n",
      "validation_loss \n",
      "epoch 50: \n",
      "0.227666938446\n",
      "\n",
      "train_loss \n",
      "epoch 51: \n",
      "0.440074427597\n",
      "\n",
      "validation_loss \n",
      "epoch 51: \n",
      "0.227663338446\n",
      "\n",
      "train_loss \n",
      "epoch 52: \n",
      "0.439658627597\n",
      "\n",
      "validation_loss \n",
      "epoch 52: \n",
      "0.227659738446\n",
      "\n",
      "train_loss \n",
      "epoch 53: \n",
      "0.439242827597\n",
      "\n",
      "validation_loss \n",
      "epoch 53: \n",
      "0.227656138446\n",
      "\n",
      "train_loss \n",
      "epoch 54: \n",
      "0.438827027597\n",
      "\n",
      "validation_loss \n",
      "epoch 54: \n",
      "0.227652538446\n",
      "\n",
      "train_loss \n",
      "epoch 55: \n",
      "0.438411227597\n",
      "\n",
      "validation_loss \n",
      "epoch 55: \n",
      "0.227648938446\n",
      "\n",
      "train_loss \n",
      "epoch 56: \n",
      "0.437995427597\n",
      "\n",
      "validation_loss \n",
      "epoch 56: \n",
      "0.227645338446\n",
      "\n",
      "train_loss \n",
      "epoch 57: \n",
      "0.437579627597\n",
      "\n",
      "validation_loss \n",
      "epoch 57: \n",
      "0.227641738446\n",
      "\n",
      "train_loss \n",
      "epoch 58: \n",
      "0.437163827597\n",
      "\n",
      "validation_loss \n",
      "epoch 58: \n",
      "0.227638138446\n",
      "\n",
      "train_loss \n",
      "epoch 59: \n",
      "0.436748027597\n",
      "\n",
      "validation_loss \n",
      "epoch 59: \n",
      "0.227634538446\n",
      "\n",
      "train_loss \n",
      "epoch 60: \n",
      "0.436332227597\n",
      "\n",
      "validation_loss \n",
      "epoch 60: \n",
      "0.227630938446\n",
      "\n",
      "train_loss \n",
      "epoch 61: \n",
      "0.435916427597\n",
      "\n",
      "validation_loss \n",
      "epoch 61: \n",
      "0.227627338446\n",
      "\n",
      "train_loss \n",
      "epoch 62: \n",
      "0.435500627597\n",
      "\n",
      "validation_loss \n",
      "epoch 62: \n",
      "0.227623738446\n",
      "\n",
      "train_loss \n",
      "epoch 63: \n",
      "0.435084827597\n",
      "\n",
      "validation_loss \n",
      "epoch 63: \n",
      "0.227620138446\n",
      "\n",
      "train_loss \n",
      "epoch 64: \n",
      "0.434669027597\n",
      "\n",
      "validation_loss \n",
      "epoch 64: \n",
      "0.227616538446\n",
      "\n",
      "train_loss \n",
      "epoch 65: \n",
      "0.434253227597\n",
      "\n",
      "validation_loss \n",
      "epoch 65: \n",
      "0.227612938446\n",
      "\n",
      "train_loss \n",
      "epoch 66: \n",
      "0.433837427597\n",
      "\n",
      "validation_loss \n",
      "epoch 66: \n",
      "0.227609338446\n",
      "\n",
      "train_loss \n",
      "epoch 67: \n",
      "0.433421627597\n",
      "\n",
      "validation_loss \n",
      "epoch 67: \n",
      "0.227605738446\n",
      "\n",
      "train_loss \n",
      "epoch 68: \n",
      "0.433005827597\n",
      "\n",
      "validation_loss \n",
      "epoch 68: \n",
      "0.227602138446\n",
      "\n",
      "train_loss \n",
      "epoch 69: \n",
      "0.432590027597\n",
      "\n",
      "validation_loss \n",
      "epoch 69: \n",
      "0.227598538446\n",
      "\n",
      "train_loss \n",
      "epoch 70: \n",
      "0.432174227597\n",
      "\n",
      "validation_loss \n",
      "epoch 70: \n",
      "0.227594938446\n",
      "\n",
      "train_loss \n",
      "epoch 71: \n",
      "0.431758427597\n",
      "\n",
      "validation_loss \n",
      "epoch 71: \n",
      "0.227591338446\n",
      "\n",
      "train_loss \n",
      "epoch 72: \n",
      "0.431342627597\n",
      "\n",
      "validation_loss \n",
      "epoch 72: \n",
      "0.227587738446\n",
      "\n",
      "train_loss \n",
      "epoch 73: \n",
      "0.430926827597\n",
      "\n",
      "validation_loss \n",
      "epoch 73: \n",
      "0.227584138446\n",
      "\n",
      "train_loss \n",
      "epoch 74: \n",
      "0.430511027597\n",
      "\n",
      "validation_loss \n",
      "epoch 74: \n",
      "0.227580538446\n",
      "\n",
      "train_loss \n",
      "epoch 75: \n",
      "0.430095227597\n",
      "\n",
      "validation_loss \n",
      "epoch 75: \n",
      "0.227576938446\n",
      "\n",
      "train_loss \n",
      "epoch 76: \n",
      "0.429679427597\n",
      "\n",
      "validation_loss \n",
      "epoch 76: \n",
      "0.227573338446\n",
      "\n",
      "train_loss \n",
      "epoch 77: \n",
      "0.429263627597\n",
      "\n",
      "validation_loss \n",
      "epoch 77: \n",
      "0.227569738446\n",
      "\n",
      "train_loss \n",
      "epoch 78: \n",
      "0.428847827597\n",
      "\n",
      "validation_loss \n",
      "epoch 78: \n",
      "0.227566138446\n",
      "\n",
      "train_loss \n",
      "epoch 79: \n",
      "0.428432027597\n",
      "\n",
      "validation_loss \n",
      "epoch 79: \n",
      "0.227562538446\n",
      "\n",
      "train_loss \n",
      "epoch 80: \n",
      "0.428016227597\n",
      "\n",
      "validation_loss \n",
      "epoch 80: \n",
      "0.227558938446\n",
      "\n",
      "train_loss \n",
      "epoch 81: \n",
      "0.427600427597\n",
      "\n",
      "validation_loss \n",
      "epoch 81: \n",
      "0.227555338446\n",
      "\n",
      "train_loss \n",
      "epoch 82: \n",
      "0.427184627597\n",
      "\n",
      "validation_loss \n",
      "epoch 82: \n",
      "0.227551738446\n",
      "\n",
      "train_loss \n",
      "epoch 83: \n",
      "0.426768827597\n",
      "\n",
      "validation_loss \n",
      "epoch 83: \n",
      "0.227548138446\n",
      "\n",
      "train_loss \n",
      "epoch 84: \n",
      "0.426353027597\n",
      "\n",
      "validation_loss \n",
      "epoch 84: \n",
      "0.227544538446\n",
      "\n",
      "train_loss \n",
      "epoch 85: \n",
      "0.425937227597\n",
      "\n",
      "validation_loss \n",
      "epoch 85: \n",
      "0.227540938446\n",
      "\n",
      "train_loss \n",
      "epoch 86: \n",
      "0.425521427597\n",
      "\n",
      "validation_loss \n",
      "epoch 86: \n",
      "0.227537338446\n",
      "\n",
      "train_loss \n",
      "epoch 87: \n",
      "0.425105627597\n",
      "\n",
      "validation_loss \n",
      "epoch 87: \n",
      "0.227533738446\n",
      "\n",
      "train_loss \n",
      "epoch 88: \n",
      "0.424689827597\n",
      "\n",
      "validation_loss \n",
      "epoch 88: \n",
      "0.227530138446\n",
      "\n",
      "train_loss \n",
      "epoch 89: \n",
      "0.424274027597\n",
      "\n",
      "validation_loss \n",
      "epoch 89: \n",
      "0.227526538446\n",
      "\n",
      "train_loss \n",
      "epoch 90: \n",
      "0.423858227597\n",
      "\n",
      "validation_loss \n",
      "epoch 90: \n",
      "0.227522938446\n",
      "\n",
      "train_loss \n",
      "epoch 91: \n",
      "0.423442427597\n",
      "\n",
      "validation_loss \n",
      "epoch 91: \n",
      "0.227519338446\n",
      "\n",
      "train_loss \n",
      "epoch 92: \n",
      "0.423026627597\n",
      "\n",
      "validation_loss \n",
      "epoch 92: \n",
      "0.227515738446\n",
      "\n",
      "train_loss \n",
      "epoch 93: \n",
      "0.422610827597\n",
      "\n",
      "validation_loss \n",
      "epoch 93: \n",
      "0.227512138446\n",
      "\n",
      "train_loss \n",
      "epoch 94: \n",
      "0.422195027597\n",
      "\n",
      "validation_loss \n",
      "epoch 94: \n",
      "0.227508538446\n",
      "\n",
      "train_loss \n",
      "epoch 95: \n",
      "0.421779227597\n",
      "\n",
      "validation_loss \n",
      "epoch 95: \n",
      "0.227504938446\n",
      "\n",
      "train_loss \n",
      "epoch 96: \n",
      "0.421363427597\n",
      "\n",
      "validation_loss \n",
      "epoch 96: \n",
      "0.227501338446\n",
      "\n",
      "train_loss \n",
      "epoch 97: \n",
      "0.420947627597\n",
      "\n",
      "validation_loss \n",
      "epoch 97: \n",
      "0.227497738446\n",
      "\n",
      "train_loss \n",
      "epoch 98: \n",
      "0.420531827597\n",
      "\n",
      "validation_loss \n",
      "epoch 98: \n",
      "0.227494138446\n",
      "\n",
      "train_loss \n",
      "epoch 99: \n",
      "0.420116027597\n",
      "\n",
      "validation_loss \n",
      "epoch 99: \n",
      "0.227490538446\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISIisf4/xMYH5G6WZAkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29eba2fbc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file as load\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_loss(x,y,k):\n",
    "    n = x.shape[1]\n",
    "    total = 0\n",
    "    for z in range(x.shape[0]):\n",
    "        if np.sum((1 - y[z] * (x[z] * w + b[z]))) > 0:\n",
    "            total += np.sum((1 - y[z] * (x[z] * w + b[z])))\n",
    "    loss = np.sum(np.square(w)) / (2*n) + C * total\n",
    "    print('epoch '+ str(k) + ': ')\n",
    "    print(loss)\n",
    "    return loss\n",
    "\n",
    "#load data\n",
    "data = load('./australian_scale.txt')\n",
    "x, y = data[0], data[1]\n",
    "x_train,x_validation,y_train,y_validation = train_test_split(x,y,test_size=0.33,random_state=0)\n",
    "x_train,x_validation,y_train,y_validation = x_train.todense(),x_validation.todense(),y_train.reshape(len(y_train),-1),y_validation.reshape(len(y_validation),-1)\n",
    "\n",
    "#initialize b,w\n",
    "b = np.zeros((x_train.shape[0],1))\n",
    "w = np.empty((x_train.shape[1],1))\n",
    "\n",
    "# training\n",
    "iteration = 100\n",
    "learning_rate = 0.9\n",
    "C = 0.001\n",
    "train_loss=[] #记录每次迭代的train的loss值\n",
    "validation_loss=[] #记录每次迭代的validation的loss值\n",
    "\n",
    "for i in range(iteration):\n",
    "    for j in range(x_train.shape[0]):\n",
    "        if np.sum((1 - y_train[j] * (x_train[j] * w + b[j] ))) > 0:\n",
    "            w_gradient = w + x_train[j].T * C * (-1 * y_train[j])\n",
    "            b_gradient = -1 * C * y_train[j]\n",
    "        else:\n",
    "            w_gradient = w\n",
    "            b_gradient = 0\n",
    "        w = w - learning_rate * w_gradient\n",
    "        b[j] = b[j] - learning_rate * b_gradient\n",
    "    print('\\ntrain_loss ')\n",
    "    train_loss.append( compute_loss(x_train,y_train,i) )\n",
    "    print('\\nvalidation_loss ')\n",
    "    validation_loss.append( compute_loss(x_validation,y_validation,i) )\n",
    "\n",
    "# for plt\n",
    "t = np.arange(0, iteration, 1)\n",
    "plt.plot(t, validation_loss, color=\"blue\", linewidth=2.5, linestyle=\"-\", label=\"validation_loss\")\n",
    "plt.plot(t, train_loss, color=\"red\",  linewidth=2.5, linestyle=\"-\", label=\"train_loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.plot(t, train_loss, 'r--',t, validation_loss, 'b--')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}